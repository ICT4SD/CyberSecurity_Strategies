{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnan\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\mnan\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim import corpora\n",
    "import timeit\n",
    "from collections import defaultdict\n",
    "from nltk import PorterStemmer\n",
    "from gensim.utils import lemmatize # Only keep nums\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(sys.version_info) ### Make sure you are using Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## change dir\n",
    "os.chdir(os.getcwd()+'\\data')\n",
    "\n",
    "dict_data = {}\n",
    "country_list = []\n",
    "content_list = []        \n",
    "for i in glob.glob('*.txt'):\n",
    "    with open(i,encoding='utf-8',errors = 'ignore') as f:\n",
    "        country_list += [i.split('.')[0]]\n",
    "        content = f.readlines()\n",
    "        content_list += [''.join(list(filter(None, list(map(lambda x:x.strip(), content)))))]\n",
    "dict_data['country'] = country_list\n",
    "dict_data['content'] = content_list\n",
    "df_all = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnan\\Desktop\\un-project\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## change dir\n",
    "os.chdir(os.getcwd()+'\\profiles')\n",
    "\n",
    "dictionary_data = {}\n",
    "dict_country_list = []\n",
    "dict_content_list = []        \n",
    "for i in glob.glob('*.txt'):\n",
    "    with open(i,encoding='utf-8',errors = 'ignore') as f:\n",
    "        dict_country_list += [i.split('.')[0]]\n",
    "        dict_content = f.readlines()\n",
    "        dict_content_list += [''.join(list(filter(None, list(map(lambda x:x.strip(), dict_content)))))]\n",
    "dictionary_data['country'] = dict_country_list\n",
    "dictionary_data['content'] = dict_content_list\n",
    "dict_df_all = pd.DataFrame(dictionary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IslamicRepublicofAfghanistanMinistryofCommunic...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shkresa-KokaColorR E P U B L I K A E S H Q I P...</td>\n",
       "      <td>Albania (nonEnglish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIASCYBER SECURITY STRATEGYEnabling inno...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logo Republik sterreichLogo Bundeskanzleramt s...</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Az.rbaycan Prezidentinin R.smi internet s.hif....</td>\n",
       "      <td>Azerbaijan (nonEnglish)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                  country\n",
       "0  IslamicRepublicofAfghanistanMinistryofCommunic...              Afghanistan\n",
       "1  Shkresa-KokaColorR E P U B L I K A E S H Q I P...     Albania (nonEnglish)\n",
       "2  AUSTRALIASCYBER SECURITY STRATEGYEnabling inno...                Australia\n",
       "3  Logo Republik sterreichLogo Bundeskanzleramt s...                  Austria\n",
       "4  Az.rbaycan Prezidentinin R.smi internet s.hif....  Azerbaijan (nonEnglish)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿----------------------- Page 1---------------...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿----------------------- Page 1---------------...</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿----------------------- Page 1---------------...</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿----------------------- Page 1---------------...</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>﻿----------------------- Page 1---------------...</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content      country\n",
       "0  ﻿----------------------- Page 1---------------...  Afghanistan\n",
       "1  ﻿----------------------- Page 1---------------...      Albania\n",
       "2  ﻿----------------------- Page 1---------------...      Algeria\n",
       "3  ﻿----------------------- Page 1---------------...      Andorra\n",
       "4  ﻿----------------------- Page 1---------------...       Angola"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_text(paragraph_list):\n",
    "    \"\"\"\n",
    "    stopwords\n",
    "    \n",
    "    punctuation\n",
    "    \n",
    "    digits\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    typical_words = ['security','cyber','the','information','government'\n",
    "                     ,'cybersecurity','national','development','systems'\n",
    "                     ,'services','strategy','international','cyberspace']\n",
    "    stoplist = stopwords.words('english') + typical_words \n",
    "    \n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    remove_punctuation = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    \n",
    "    paragraph_cleaned =[i.translate(remove_digits) for i in paragraph_list]\n",
    "    \n",
    "    paragraph_cleaned = [i.translate(remove_punctuation) for i in paragraph_cleaned]\n",
    "    \n",
    "    paragraph_cleaned = [[lemma.lemmatize(word.lower()) for word in line.split() \n",
    "                          if (word.lower() not in stoplist and len(word)>4)] for line in paragraph_cleaned]\n",
    "\n",
    "    return paragraph_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph_cleaned = process_text(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_paragraph_cleaned = process_text(dict_content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(dict_paragraph_cleaned,min_count=1, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnan\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:248: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "dictionary_text_list = list(bigram[dict_paragraph_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnan\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:248: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "train_text_list = list(bigram[paragraph_cleaned])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictionary built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(dictionary_text_list)\n",
    "corpus = [dictionary.doc2bow(text) for text in train_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mnan\\\\Desktop\\\\un-project\\\\profiles'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnan\\Desktop\\un-project\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lda modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_num = 5\n",
    "lda = LdaModel(corpus, num_topics= topic_num,id2word = dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dump "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lda.pickle', 'wb') as handle:\n",
    "    pickle.dump(lda, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('corpus.pickle', 'wb') as handle:\n",
    "    pickle.dump(corpus, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
